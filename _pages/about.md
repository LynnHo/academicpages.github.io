---
permalink: /
title: "何振梁（Zhenliang He）"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am an Assistant Professor in the [Visual Information Processing and Learning (VIPL)](http://vipl.ict.ac.cn/en) research group at the [Institute of Computing Technology (ICT), Chinese Academy of Sciences (CAS)](http://www.ict.cas.cn). I received my Ph.D. from ICT, CAS in 2021, under the supervision of Prof. [Shiguang Shan](https://vipl.ict.ac.cn/people/~sgshan) and close collaboration with Prof. [Meina Kan](https://vipl.ict.ac.cn/homepage/mnkan/index.html) and Prof. [Xilin Chen](https://vipl.ict.ac.cn/people/~xlchen). I received my B.E. from Beijing University of Posts and Telecommunications in 2015. My current research focuses on generative models and representation learning.

<a href="https://scholar.google.com/citations?user=fDTTEaAAAAAJ"><img src="images/google-scholar.png" width="25"></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/LynnHo"><img src="https://img.icons8.com/ios-filled/50/null/github.svg" width="25"></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="mailto:hezhenliang@ict.ac.cn"><img src="images/email.png" width="25"></a>&nbsp;[<font size="4">hezhenliang@ict.ac.cn</font>](mailto:hezhenliang@ict.ac.cn)


---

Tutorial
======

+ [Matrix Calculus (Matrix Derivative, 矩阵求导教程)](https://github.com/LynnHo/Matrix-Calculus-Tutorial)

  <a href="https://github.com/LynnHo/Matrix-Calculus-Tutorial"><img src="https://user-images.githubusercontent.com/16457298/147549423-70e1561b-be2e-4392-9ee1-e9aa5ec0bdfe.png" width="20%"></a>

---

Selected Publications
======

*See the full list on [Google Scholar](https://scholar.google.com/citations?user=fDTTEaAAAAAJ)*


<!--EigenGAN-->
<table>
    <td width="1000"><a href="https://github.com/LynnHo/EigenGAN-Tensorflow"><img src="0_lynn/projects/eigengan/eigengan.gif" width="1000"></a></td>
    
    <td width="4000">
        <p class="content"><strong>EigenGAN: Layer-Wise Eigen-Learning for GANs</strong></p>
        <p class="content"><strong>Zhenliang He</strong>, Meina Kan, Shiguang Shan</p>
        <p class="content"><img src="https://img.shields.io/badge/ICCV%202021-3A98B9" height="40">&nbsp;&nbsp;&nbsp;<img src="https://img.shields.io/github/stars/LynnHo/EigenGAN-Tensorflow.svg?style=social" height="40"> </p>

        <a href="https://github.com/LynnHo/EigenGAN-Tensorflow">Project</a> |
        <a href="https://arxiv.org/pdf/2104.12476.pdf">Paper</a> |
        <a href="https://www.youtube.com/watch?v=E_88BajgIOs">Video</a> |
        <a href="https://github.com/LynnHo/EigenGAN-Tensorflow">TensorFlow (Official)</a> |
        <a href="https://github.com/bryandlee/eigengan-pytorch">PyTorch</a> |
        <a href="0_lynn/projects/eigengan/eigengan.txt">Bib</a>
    </td>
</table>

<!--AttGAN-->
<table>
    <td width="1000"><a href="https://github.com/LynnHo/AttGAN-Tensorflow"><img src="0_lynn/projects/attgan/attgan.jpg" width="1000"></a></td>
    
    <td width="4000">
        <p class="content"><strong>AttGAN: Facial Attribute Editing by Only Changing What You Want</strong></p>
        <p class="content"><strong>Zhenliang He</strong>, Wangmeng Zuo, Meina Kan, Shiguang Shan, Xilin Chen</p>
        <p class="content"><img src="https://img.shields.io/badge/T--IP%202019-3A98B9" height="40">&nbsp;&nbsp;&nbsp;<img src="https://img.shields.io/github/stars/LynnHo/AttGAN-Tensorflow.svg?style=social" height="40"> </p>
        
        <a href="https://github.com/LynnHo/AttGAN-Tensorflow">Project</a> |
        <a href="https://vipl.ict.ac.cn/publications/2019/jour/202212/P020221230369682856969.pdf">Paper</a> |
        <a href="https://github.com/LynnHo/AttGAN-Tensorflow">TensorFlow (Official)</a> |
        <a href="https://github.com/elvisyjlin/AttGAN-PyTorch">PyTorch</a> |
        <a href="https://www.paddlepaddle.org.cn/modelbasedetail/attgan">PaddlePaddle</a> |
        <a href="0_lynn/projects/attgan/attgan.txt">Bib</a>
    </td>
</table>

<!--S2GAN-->
<table>
    <td width="1000"><a href="https://openaccess.thecvf.com/content_ICCV_2019/html/He_S2GAN_Share_Aging_Factors_Across_Ages_and_Share_Aging_Trends_ICCV_2019_paper.html"><img src="0_lynn/projects/s2gan/s2gan.jpg" width="1000"></a></td>
    
    <td width="4000">
        <p class="content"><strong>S2GAN: Share Aging Factors Across Ages and Share Aging Trends Among Individuals</strong></p>
        <p class="content"><strong>Zhenliang He</strong>, Meina Kan, Shiguang Shan, Xilin Chen</p>
        <p class="content"><img src="https://img.shields.io/badge/Oral-FFF1DC?label=ICCV%202019&labelColor=3A98B9" height="40"> </p>
        
        <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/He_S2GAN_Share_Aging_Factors_Across_Ages_and_Share_Aging_Trends_ICCV_2019_paper.pdf">Paper</a> |
        <a href="https://www.youtube.com/watch?v=ByfFufRhuRc">Video</a> |
        <a href="0_lynn/projects/s2gan/s2gan.txt">Bib</a>
    </td>
</table>

<!--PA-GAN-->
<table>
    <td width="1000"><a href="https://github.com/LynnHo/PA-GAN-Tensorflow"><img src="0_lynn/projects/pa-gan/pa-gan.jpg" width="1000"></a></td>
    
    <td width="4000">
        <p class="content"><strong>PA-GAN: Progressive Attention Generative Adversarial Network for Facial Attribute Editing</strong></p>
        <p class="content"><strong>Zhenliang He</strong>, Meina Kan, Jichao Zhang, Shiguang Shan</p>
        <p class="content"><img src="https://img.shields.io/badge/arXiv-3A98B9" height="40"> </p>
        
        <a href="https://github.com/LynnHo/PA-GAN-Tensorflow">Project</a> |
        <a href="https://arxiv.org/pdf/2007.05892.pdf">Paper</a> |
        <a href="https://github.com/LynnHo/PA-GAN-Tensorflow">Code</a> |
        <a href="0_lynn/projects/pa-gan/pa-gan.txt">Bib</a>
    </td>
</table>


<!--STD-GAN-->
<table>
    <td width="1000"><a href="0_lynn/projects/std-gan/std-gan.pdf"><img src="0_lynn/projects/std-gan/std-gan.jpg" width="1000"></a></td>
    
    <td width="4000">
        <p class="content"><strong>Image Style Disentangling for Instance-Level Facial Attribute Transfer</strong></p>
        <p class="content">Xuyang Guo, Meina Kan, <strong>Zhenliang He</strong>, Xingguang Song, Shiguang Shan</p>
        <p class="content"><img src="https://img.shields.io/badge/CVIU%202021-3A98B9" height="40"></p>
        
        <a href="https://github.com/XuyangGuo/STD-GAN">Project</a> |
        <a href="0_lynn/projects/std-gan/std-gan.pdf">Paper</a> |
        <a href="0_lynn/projects/std-gan/std-gan.txt">Bib</a>
    </td>
</table>


---

Education & Experience
======

+ 2023.04 - now, Assistant Professor in the [Visual Information Processing and Learning (VIPL)](http://vipl.ict.ac.cn/en) research group at the [Institute of Computing Technology (ICT), Chinese Academy of Sciences (CAS)](http://www.ict.cas.cn).
+ 2021.08 - 2023-03, Research Engineer at JD.com, Inc.
+ 2015.09 - 2021.06, Ph.D. student at the Institute of Computing Technology (ICT), Chinese Academy of Sciences (CAS), under the supervision of Prof. [Shiguang Shan](https://vipl.ict.ac.cn/people/~sgshan). I also had close collaboration with Prof. [Meina Kan](https://vipl.ict.ac.cn/homepage/mnkan/index.html) and Prof. [Xilin Chen](https://vipl.ict.ac.cn/people/~xlchen).
+ 2011.09 - 2015.07, college student at Beijing University of Posts and Telecommunications.


---

Honors & Awards
======

+ Outstanding Graduates Award of Beijing, ICT, CAS, 2021
+ Special Scholarship of ICT (**highest award in ICT**), ICT, CAS, 2019
+ Huawei Excellent Cooperation Award, 2017
+ Second Place Winner of MENPO Challenge in CVPR 2017
+ First Prize of Beijing Higher Mathematics Competition, 2012
+ National Scholarship (**top 8 of 610 students**), BUPT, 2012 & 2014
